{
  "version": 3,
  "sources": ["../src/browser-polyfill.ts", "../src/url.ts", "../../../node_modules/diff/lib/index.mjs", "../../scrapbox-loader/src/index.ts", "../src/scrapboxUserScript.ts"],
  "sourcesContent": ["// Browser API compatibility layer with Safari-specific enhancements\n\n// Type for Safari-specific properties\ninterface SafariExtensions {\n  _isSafari?: boolean;\n  _isIOS?: boolean;\n}\n\n// Create a browser API wrapper\nexport const browser = (() => {\n  // Use native browser API if available (Safari)\n  if (typeof (globalThis as any).browser !== 'undefined') {\n    const api = (globalThis as any).browser;\n    \n    // Add Safari detection properties\n    api._isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);\n    api._isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !(window as any).MSStream;\n    \n    return api;\n  }\n  \n  // Use chrome API if available (Chrome/Edge)\n  if (typeof (globalThis as any).chrome !== 'undefined' && (globalThis as any).chrome.runtime) {\n    const api = (globalThis as any).chrome;\n    \n    // Add Safari detection properties (will be false)\n    api._isSafari = false;\n    api._isIOS = false;\n    \n    return api;\n  }\n  \n  // If neither is available, we're in a bad state\n  console.error(\"No browser extension API found!\");\n  \n  // Return a minimal mock to prevent crashes\n  return {\n    _isSafari: /^((?!chrome|android).)*safari/i.test(navigator.userAgent),\n    _isIOS: /iPad|iPhone|iPod/.test(navigator.userAgent) && !(window as any).MSStream,\n    runtime: {\n      onMessage: { addListener: () => {} },\n      sendMessage: () => Promise.resolve(),\n      getURL: (path: string) => path\n    },\n    storage: {\n      sync: {\n        get: () => Promise.resolve({}),\n        set: () => Promise.resolve()\n      },\n      local: {\n        get: () => Promise.resolve({}),\n        set: () => Promise.resolve()\n      }\n    },\n    action: {\n      onClicked: { addListener: () => {} }\n    },\n    tabs: {\n      sendMessage: () => Promise.resolve(),\n      query: () => Promise.resolve([])\n    }\n  } as any;\n})();\n\n// Also export as chrome for compatibility\nexport const chrome = browser;\n\n// Safari-specific API fallbacks and utilities\nexport const safariCompat = {\n  // Safari doesn't support browser.runtime.openOptionsPage on iOS\n  openOptionsPage: async (): Promise<void> => {\n    try {\n      if (browser.runtime.openOptionsPage && !browser._isIOS) {\n        await browser.runtime.openOptionsPage();\n      } else {\n        // Fallback: open in new tab\n        const optionsUrl = browser.runtime.getURL(\"options.html\");\n        await browser.tabs.create({ url: optionsUrl });\n      }\n    } catch (error) {\n      console.error(\"[safariCompat] Failed to open options page:\", error);\n      // Last resort: try to open in current tab\n      const optionsUrl = browser.runtime.getURL(\"options.html\");\n      window.open(optionsUrl, \"_blank\");\n    }\n  },\n  \n  // Check if running on Safari\n  isSafari: (): boolean => browser._isSafari || false,\n  \n  // Check if running on iOS\n  isIOS: (): boolean => browser._isIOS || false,\n  \n  // Safari storage fallbacks (Safari has 10MB limit vs Chrome's unlimited)\n  safeStorageSet: async (items: Record<string, any>): Promise<void> => {\n    try {\n      await browser.storage.local.set(items);\n    } catch (error: any) {\n      if (error.message?.includes(\"quota\")) {\n        console.error(\"[safariCompat] Storage quota exceeded, attempting cleanup...\");\n        // Try to clear old data\n        const keys = Object.keys(await browser.storage.local.get());\n        if (keys.length > 100) {\n          // Remove oldest entries (assuming keys have timestamps)\n          const toRemove = keys.slice(0, Math.floor(keys.length * 0.2));\n          await browser.storage.local.remove(toRemove);\n          // Retry\n          await browser.storage.local.set(items);\n        }\n      } else {\n        throw error;\n      }\n    }\n  },\n  \n  // Context menus compatibility (not supported on iOS)\n  supportsContextMenus: (): boolean => {\n    return !browser._isIOS && typeof browser.contextMenus !== \"undefined\";\n  },\n  \n  // Permissions check with Safari fallbacks\n  hasPermission: async (permission: string): Promise<boolean> => {\n    if (!browser.permissions?.contains) {\n      console.warn(\"[safariCompat] Permissions API not available\");\n      return false;\n    }\n    \n    try {\n      const result = await browser.permissions.contains({ permissions: [permission] });\n      return result;\n    } catch (error) {\n      console.error(`[safariCompat] Failed to check permission ${permission}:`, error);\n      return false;\n    }\n  }\n};\n\n// Make browser API available globally if needed\ndeclare global {\n  interface Window {\n    browser?: any;\n    chrome?: any;\n  }\n}\n\nif (typeof (globalThis as any).browser === \"undefined\") {\n  (globalThis as any).browser = browser;\n}\nif (typeof (globalThis as any).chrome === \"undefined\") {\n  (globalThis as any).chrome = browser;\n}", "export const encodeForScrapboxReadableLink = (uriComponent: string) => {\n  let encoded = encodeURIComponent(uriComponent);\n\n  encoded = encoded.replaceAll(\"%20\", \"+\");\n\n  for (const match of uriComponent.matchAll(\n    /[\\p{scx=Hiragana}\\p{scx=Katakana}\\p{scx=Han}]/gu\n  )) {\n    encoded = encoded.replace(encodeURIComponent(match[0]), match[0]);\n  }\n\n  return encoded;\n};\n", "function Diff() {}\nDiff.prototype = {\n  diff: function diff(oldString, newString) {\n    var _options$timeout;\n\n    var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    var callback = options.callback;\n\n    if (typeof options === 'function') {\n      callback = options;\n      options = {};\n    }\n\n    this.options = options;\n    var self = this;\n\n    function done(value) {\n      if (callback) {\n        setTimeout(function () {\n          callback(undefined, value);\n        }, 0);\n        return true;\n      } else {\n        return value;\n      }\n    } // Allow subclasses to massage the input prior to running\n\n\n    oldString = this.castInput(oldString);\n    newString = this.castInput(newString);\n    oldString = this.removeEmpty(this.tokenize(oldString));\n    newString = this.removeEmpty(this.tokenize(newString));\n    var newLen = newString.length,\n        oldLen = oldString.length;\n    var editLength = 1;\n    var maxEditLength = newLen + oldLen;\n\n    if (options.maxEditLength) {\n      maxEditLength = Math.min(maxEditLength, options.maxEditLength);\n    }\n\n    var maxExecutionTime = (_options$timeout = options.timeout) !== null && _options$timeout !== void 0 ? _options$timeout : Infinity;\n    var abortAfterTimestamp = Date.now() + maxExecutionTime;\n    var bestPath = [{\n      oldPos: -1,\n      lastComponent: undefined\n    }]; // Seed editLength = 0, i.e. the content starts with the same values\n\n    var newPos = this.extractCommon(bestPath[0], newString, oldString, 0);\n\n    if (bestPath[0].oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n      // Identity per the equality and tokenizer\n      return done([{\n        value: this.join(newString),\n        count: newString.length\n      }]);\n    } // Once we hit the right edge of the edit graph on some diagonal k, we can\n    // definitely reach the end of the edit graph in no more than k edits, so\n    // there's no point in considering any moves to diagonal k+1 any more (from\n    // which we're guaranteed to need at least k+1 more edits).\n    // Similarly, once we've reached the bottom of the edit graph, there's no\n    // point considering moves to lower diagonals.\n    // We record this fact by setting minDiagonalToConsider and\n    // maxDiagonalToConsider to some finite value once we've hit the edge of\n    // the edit graph.\n    // This optimization is not faithful to the original algorithm presented in\n    // Myers's paper, which instead pointlessly extends D-paths off the end of\n    // the edit graph - see page 7 of Myers's paper which notes this point\n    // explicitly and illustrates it with a diagram. This has major performance\n    // implications for some common scenarios. For instance, to compute a diff\n    // where the new text simply appends d characters on the end of the\n    // original text of length n, the true Myers algorithm will take O(n+d^2)\n    // time while this optimization needs only O(n+d) time.\n\n\n    var minDiagonalToConsider = -Infinity,\n        maxDiagonalToConsider = Infinity; // Main worker method. checks all permutations of a given edit length for acceptance.\n\n    function execEditLength() {\n      for (var diagonalPath = Math.max(minDiagonalToConsider, -editLength); diagonalPath <= Math.min(maxDiagonalToConsider, editLength); diagonalPath += 2) {\n        var basePath = void 0;\n        var removePath = bestPath[diagonalPath - 1],\n            addPath = bestPath[diagonalPath + 1];\n\n        if (removePath) {\n          // No one else is going to attempt to use this value, clear it\n          bestPath[diagonalPath - 1] = undefined;\n        }\n\n        var canAdd = false;\n\n        if (addPath) {\n          // what newPos will be after we do an insertion:\n          var addPathNewPos = addPath.oldPos - diagonalPath;\n          canAdd = addPath && 0 <= addPathNewPos && addPathNewPos < newLen;\n        }\n\n        var canRemove = removePath && removePath.oldPos + 1 < oldLen;\n\n        if (!canAdd && !canRemove) {\n          // If this path is a terminal then prune\n          bestPath[diagonalPath] = undefined;\n          continue;\n        } // Select the diagonal that we want to branch from. We select the prior\n        // path whose position in the old string is the farthest from the origin\n        // and does not pass the bounds of the diff graph\n        // TODO: Remove the `+ 1` here to make behavior match Myers algorithm\n        //       and prefer to order removals before insertions.\n\n\n        if (!canRemove || canAdd && removePath.oldPos + 1 < addPath.oldPos) {\n          basePath = self.addToPath(addPath, true, undefined, 0);\n        } else {\n          basePath = self.addToPath(removePath, undefined, true, 1);\n        }\n\n        newPos = self.extractCommon(basePath, newString, oldString, diagonalPath);\n\n        if (basePath.oldPos + 1 >= oldLen && newPos + 1 >= newLen) {\n          // If we have hit the end of both strings, then we are done\n          return done(buildValues(self, basePath.lastComponent, newString, oldString, self.useLongestToken));\n        } else {\n          bestPath[diagonalPath] = basePath;\n\n          if (basePath.oldPos + 1 >= oldLen) {\n            maxDiagonalToConsider = Math.min(maxDiagonalToConsider, diagonalPath - 1);\n          }\n\n          if (newPos + 1 >= newLen) {\n            minDiagonalToConsider = Math.max(minDiagonalToConsider, diagonalPath + 1);\n          }\n        }\n      }\n\n      editLength++;\n    } // Performs the length of edit iteration. Is a bit fugly as this has to support the\n    // sync and async mode which is never fun. Loops over execEditLength until a value\n    // is produced, or until the edit length exceeds options.maxEditLength (if given),\n    // in which case it will return undefined.\n\n\n    if (callback) {\n      (function exec() {\n        setTimeout(function () {\n          if (editLength > maxEditLength || Date.now() > abortAfterTimestamp) {\n            return callback();\n          }\n\n          if (!execEditLength()) {\n            exec();\n          }\n        }, 0);\n      })();\n    } else {\n      while (editLength <= maxEditLength && Date.now() <= abortAfterTimestamp) {\n        var ret = execEditLength();\n\n        if (ret) {\n          return ret;\n        }\n      }\n    }\n  },\n  addToPath: function addToPath(path, added, removed, oldPosInc) {\n    var last = path.lastComponent;\n\n    if (last && last.added === added && last.removed === removed) {\n      return {\n        oldPos: path.oldPos + oldPosInc,\n        lastComponent: {\n          count: last.count + 1,\n          added: added,\n          removed: removed,\n          previousComponent: last.previousComponent\n        }\n      };\n    } else {\n      return {\n        oldPos: path.oldPos + oldPosInc,\n        lastComponent: {\n          count: 1,\n          added: added,\n          removed: removed,\n          previousComponent: last\n        }\n      };\n    }\n  },\n  extractCommon: function extractCommon(basePath, newString, oldString, diagonalPath) {\n    var newLen = newString.length,\n        oldLen = oldString.length,\n        oldPos = basePath.oldPos,\n        newPos = oldPos - diagonalPath,\n        commonCount = 0;\n\n    while (newPos + 1 < newLen && oldPos + 1 < oldLen && this.equals(newString[newPos + 1], oldString[oldPos + 1])) {\n      newPos++;\n      oldPos++;\n      commonCount++;\n    }\n\n    if (commonCount) {\n      basePath.lastComponent = {\n        count: commonCount,\n        previousComponent: basePath.lastComponent\n      };\n    }\n\n    basePath.oldPos = oldPos;\n    return newPos;\n  },\n  equals: function equals(left, right) {\n    if (this.options.comparator) {\n      return this.options.comparator(left, right);\n    } else {\n      return left === right || this.options.ignoreCase && left.toLowerCase() === right.toLowerCase();\n    }\n  },\n  removeEmpty: function removeEmpty(array) {\n    var ret = [];\n\n    for (var i = 0; i < array.length; i++) {\n      if (array[i]) {\n        ret.push(array[i]);\n      }\n    }\n\n    return ret;\n  },\n  castInput: function castInput(value) {\n    return value;\n  },\n  tokenize: function tokenize(value) {\n    return value.split('');\n  },\n  join: function join(chars) {\n    return chars.join('');\n  }\n};\n\nfunction buildValues(diff, lastComponent, newString, oldString, useLongestToken) {\n  // First we convert our linked list of components in reverse order to an\n  // array in the right order:\n  var components = [];\n  var nextComponent;\n\n  while (lastComponent) {\n    components.push(lastComponent);\n    nextComponent = lastComponent.previousComponent;\n    delete lastComponent.previousComponent;\n    lastComponent = nextComponent;\n  }\n\n  components.reverse();\n  var componentPos = 0,\n      componentLen = components.length,\n      newPos = 0,\n      oldPos = 0;\n\n  for (; componentPos < componentLen; componentPos++) {\n    var component = components[componentPos];\n\n    if (!component.removed) {\n      if (!component.added && useLongestToken) {\n        var value = newString.slice(newPos, newPos + component.count);\n        value = value.map(function (value, i) {\n          var oldValue = oldString[oldPos + i];\n          return oldValue.length > value.length ? oldValue : value;\n        });\n        component.value = diff.join(value);\n      } else {\n        component.value = diff.join(newString.slice(newPos, newPos + component.count));\n      }\n\n      newPos += component.count; // Common case\n\n      if (!component.added) {\n        oldPos += component.count;\n      }\n    } else {\n      component.value = diff.join(oldString.slice(oldPos, oldPos + component.count));\n      oldPos += component.count; // Reverse add and remove so removes are output first to match common convention\n      // The diffing algorithm is tied to add then remove output and this is the simplest\n      // route to get the desired output with minimal overhead.\n\n      if (componentPos && components[componentPos - 1].added) {\n        var tmp = components[componentPos - 1];\n        components[componentPos - 1] = components[componentPos];\n        components[componentPos] = tmp;\n      }\n    }\n  } // Special case handle for when one terminal is ignored (i.e. whitespace).\n  // For this case we merge the terminal into the prior string and drop the change.\n  // This is only available for string mode.\n\n\n  var finalComponent = components[componentLen - 1];\n\n  if (componentLen > 1 && typeof finalComponent.value === 'string' && (finalComponent.added || finalComponent.removed) && diff.equals('', finalComponent.value)) {\n    components[componentLen - 2].value += finalComponent.value;\n    components.pop();\n  }\n\n  return components;\n}\n\nvar characterDiff = new Diff();\nfunction diffChars(oldStr, newStr, options) {\n  return characterDiff.diff(oldStr, newStr, options);\n}\n\nfunction generateOptions(options, defaults) {\n  if (typeof options === 'function') {\n    defaults.callback = options;\n  } else if (options) {\n    for (var name in options) {\n      /* istanbul ignore else */\n      if (options.hasOwnProperty(name)) {\n        defaults[name] = options[name];\n      }\n    }\n  }\n\n  return defaults;\n}\n\n//\n// Ranges and exceptions:\n// Latin-1 Supplement, 0080\u201300FF\n//  - U+00D7  \u00D7 Multiplication sign\n//  - U+00F7  \u00F7 Division sign\n// Latin Extended-A, 0100\u2013017F\n// Latin Extended-B, 0180\u2013024F\n// IPA Extensions, 0250\u201302AF\n// Spacing Modifier Letters, 02B0\u201302FF\n//  - U+02C7  \u02C7 &#711;  Caron\n//  - U+02D8  \u02D8 &#728;  Breve\n//  - U+02D9  \u02D9 &#729;  Dot Above\n//  - U+02DA  \u02DA &#730;  Ring Above\n//  - U+02DB  \u02DB &#731;  Ogonek\n//  - U+02DC  \u02DC &#732;  Small Tilde\n//  - U+02DD  \u02DD &#733;  Double Acute Accent\n// Latin Extended Additional, 1E00\u20131EFF\n\nvar extendedWordChars = /^[A-Za-z\\xC0-\\u02C6\\u02C8-\\u02D7\\u02DE-\\u02FF\\u1E00-\\u1EFF]+$/;\nvar reWhitespace = /\\S/;\nvar wordDiff = new Diff();\n\nwordDiff.equals = function (left, right) {\n  if (this.options.ignoreCase) {\n    left = left.toLowerCase();\n    right = right.toLowerCase();\n  }\n\n  return left === right || this.options.ignoreWhitespace && !reWhitespace.test(left) && !reWhitespace.test(right);\n};\n\nwordDiff.tokenize = function (value) {\n  // All whitespace symbols except newline group into one token, each newline - in separate token\n  var tokens = value.split(/([^\\S\\r\\n]+|[()[\\]{}'\"\\r\\n]|\\b)/); // Join the boundary splits that we do not consider to be boundaries. This is primarily the extended Latin character set.\n\n  for (var i = 0; i < tokens.length - 1; i++) {\n    // If we have an empty string in the next field and we have only word chars before and after, merge\n    if (!tokens[i + 1] && tokens[i + 2] && extendedWordChars.test(tokens[i]) && extendedWordChars.test(tokens[i + 2])) {\n      tokens[i] += tokens[i + 2];\n      tokens.splice(i + 1, 2);\n      i--;\n    }\n  }\n\n  return tokens;\n};\n\nfunction diffWords(oldStr, newStr, options) {\n  options = generateOptions(options, {\n    ignoreWhitespace: true\n  });\n  return wordDiff.diff(oldStr, newStr, options);\n}\nfunction diffWordsWithSpace(oldStr, newStr, options) {\n  return wordDiff.diff(oldStr, newStr, options);\n}\n\nvar lineDiff = new Diff();\n\nlineDiff.tokenize = function (value) {\n  if (this.options.stripTrailingCr) {\n    // remove one \\r before \\n to match GNU diff's --strip-trailing-cr behavior\n    value = value.replace(/\\r\\n/g, '\\n');\n  }\n\n  var retLines = [],\n      linesAndNewlines = value.split(/(\\n|\\r\\n)/); // Ignore the final empty token that occurs if the string ends with a new line\n\n  if (!linesAndNewlines[linesAndNewlines.length - 1]) {\n    linesAndNewlines.pop();\n  } // Merge the content and line separators into single tokens\n\n\n  for (var i = 0; i < linesAndNewlines.length; i++) {\n    var line = linesAndNewlines[i];\n\n    if (i % 2 && !this.options.newlineIsToken) {\n      retLines[retLines.length - 1] += line;\n    } else {\n      if (this.options.ignoreWhitespace) {\n        line = line.trim();\n      }\n\n      retLines.push(line);\n    }\n  }\n\n  return retLines;\n};\n\nfunction diffLines(oldStr, newStr, callback) {\n  return lineDiff.diff(oldStr, newStr, callback);\n}\nfunction diffTrimmedLines(oldStr, newStr, callback) {\n  var options = generateOptions(callback, {\n    ignoreWhitespace: true\n  });\n  return lineDiff.diff(oldStr, newStr, options);\n}\n\nvar sentenceDiff = new Diff();\n\nsentenceDiff.tokenize = function (value) {\n  return value.split(/(\\S.+?[.!?])(?=\\s+|$)/);\n};\n\nfunction diffSentences(oldStr, newStr, callback) {\n  return sentenceDiff.diff(oldStr, newStr, callback);\n}\n\nvar cssDiff = new Diff();\n\ncssDiff.tokenize = function (value) {\n  return value.split(/([{}:;,]|\\s+)/);\n};\n\nfunction diffCss(oldStr, newStr, callback) {\n  return cssDiff.diff(oldStr, newStr, callback);\n}\n\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function (obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function (obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n\n  return _typeof(obj);\n}\n\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n}\n\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n\n  return keys;\n}\n\nfunction _objectSpread2(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        _defineProperty(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n\n  return target;\n}\n\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\n\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\n\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && Symbol.iterator in Object(iter)) return Array.from(iter);\n}\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\n\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i];\n\n  return arr2;\n}\n\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nvar objectPrototypeToString = Object.prototype.toString;\nvar jsonDiff = new Diff(); // Discriminate between two lines of pretty-printed, serialized JSON where one of them has a\n// dangling comma and the other doesn't. Turns out including the dangling comma yields the nicest output:\n\njsonDiff.useLongestToken = true;\njsonDiff.tokenize = lineDiff.tokenize;\n\njsonDiff.castInput = function (value) {\n  var _this$options = this.options,\n      undefinedReplacement = _this$options.undefinedReplacement,\n      _this$options$stringi = _this$options.stringifyReplacer,\n      stringifyReplacer = _this$options$stringi === void 0 ? function (k, v) {\n    return typeof v === 'undefined' ? undefinedReplacement : v;\n  } : _this$options$stringi;\n  return typeof value === 'string' ? value : JSON.stringify(canonicalize(value, null, null, stringifyReplacer), stringifyReplacer, '  ');\n};\n\njsonDiff.equals = function (left, right) {\n  return Diff.prototype.equals.call(jsonDiff, left.replace(/,([\\r\\n])/g, '$1'), right.replace(/,([\\r\\n])/g, '$1'));\n};\n\nfunction diffJson(oldObj, newObj, options) {\n  return jsonDiff.diff(oldObj, newObj, options);\n} // This function handles the presence of circular references by bailing out when encountering an\n// object that is already on the \"stack\" of items being processed. Accepts an optional replacer\n\nfunction canonicalize(obj, stack, replacementStack, replacer, key) {\n  stack = stack || [];\n  replacementStack = replacementStack || [];\n\n  if (replacer) {\n    obj = replacer(key, obj);\n  }\n\n  var i;\n\n  for (i = 0; i < stack.length; i += 1) {\n    if (stack[i] === obj) {\n      return replacementStack[i];\n    }\n  }\n\n  var canonicalizedObj;\n\n  if ('[object Array]' === objectPrototypeToString.call(obj)) {\n    stack.push(obj);\n    canonicalizedObj = new Array(obj.length);\n    replacementStack.push(canonicalizedObj);\n\n    for (i = 0; i < obj.length; i += 1) {\n      canonicalizedObj[i] = canonicalize(obj[i], stack, replacementStack, replacer, key);\n    }\n\n    stack.pop();\n    replacementStack.pop();\n    return canonicalizedObj;\n  }\n\n  if (obj && obj.toJSON) {\n    obj = obj.toJSON();\n  }\n\n  if (_typeof(obj) === 'object' && obj !== null) {\n    stack.push(obj);\n    canonicalizedObj = {};\n    replacementStack.push(canonicalizedObj);\n\n    var sortedKeys = [],\n        _key;\n\n    for (_key in obj) {\n      /* istanbul ignore else */\n      if (obj.hasOwnProperty(_key)) {\n        sortedKeys.push(_key);\n      }\n    }\n\n    sortedKeys.sort();\n\n    for (i = 0; i < sortedKeys.length; i += 1) {\n      _key = sortedKeys[i];\n      canonicalizedObj[_key] = canonicalize(obj[_key], stack, replacementStack, replacer, _key);\n    }\n\n    stack.pop();\n    replacementStack.pop();\n  } else {\n    canonicalizedObj = obj;\n  }\n\n  return canonicalizedObj;\n}\n\nvar arrayDiff = new Diff();\n\narrayDiff.tokenize = function (value) {\n  return value.slice();\n};\n\narrayDiff.join = arrayDiff.removeEmpty = function (value) {\n  return value;\n};\n\nfunction diffArrays(oldArr, newArr, callback) {\n  return arrayDiff.diff(oldArr, newArr, callback);\n}\n\nfunction parsePatch(uniDiff) {\n  var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n  var diffstr = uniDiff.split(/\\r\\n|[\\n\\v\\f\\r\\x85]/),\n      delimiters = uniDiff.match(/\\r\\n|[\\n\\v\\f\\r\\x85]/g) || [],\n      list = [],\n      i = 0;\n\n  function parseIndex() {\n    var index = {};\n    list.push(index); // Parse diff metadata\n\n    while (i < diffstr.length) {\n      var line = diffstr[i]; // File header found, end parsing diff metadata\n\n      if (/^(\\-\\-\\-|\\+\\+\\+|@@)\\s/.test(line)) {\n        break;\n      } // Diff index\n\n\n      var header = /^(?:Index:|diff(?: -r \\w+)+)\\s+(.+?)\\s*$/.exec(line);\n\n      if (header) {\n        index.index = header[1];\n      }\n\n      i++;\n    } // Parse file headers if they are defined. Unified diff requires them, but\n    // there's no technical issues to have an isolated hunk without file header\n\n\n    parseFileHeader(index);\n    parseFileHeader(index); // Parse hunks\n\n    index.hunks = [];\n\n    while (i < diffstr.length) {\n      var _line = diffstr[i];\n\n      if (/^(Index:|diff|\\-\\-\\-|\\+\\+\\+)\\s/.test(_line)) {\n        break;\n      } else if (/^@@/.test(_line)) {\n        index.hunks.push(parseHunk());\n      } else if (_line && options.strict) {\n        // Ignore unexpected content unless in strict mode\n        throw new Error('Unknown line ' + (i + 1) + ' ' + JSON.stringify(_line));\n      } else {\n        i++;\n      }\n    }\n  } // Parses the --- and +++ headers, if none are found, no lines\n  // are consumed.\n\n\n  function parseFileHeader(index) {\n    var fileHeader = /^(---|\\+\\+\\+)\\s+(.*)$/.exec(diffstr[i]);\n\n    if (fileHeader) {\n      var keyPrefix = fileHeader[1] === '---' ? 'old' : 'new';\n      var data = fileHeader[2].split('\\t', 2);\n      var fileName = data[0].replace(/\\\\\\\\/g, '\\\\');\n\n      if (/^\".*\"$/.test(fileName)) {\n        fileName = fileName.substr(1, fileName.length - 2);\n      }\n\n      index[keyPrefix + 'FileName'] = fileName;\n      index[keyPrefix + 'Header'] = (data[1] || '').trim();\n      i++;\n    }\n  } // Parses a hunk\n  // This assumes that we are at the start of a hunk.\n\n\n  function parseHunk() {\n    var chunkHeaderIndex = i,\n        chunkHeaderLine = diffstr[i++],\n        chunkHeader = chunkHeaderLine.split(/@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@/);\n    var hunk = {\n      oldStart: +chunkHeader[1],\n      oldLines: typeof chunkHeader[2] === 'undefined' ? 1 : +chunkHeader[2],\n      newStart: +chunkHeader[3],\n      newLines: typeof chunkHeader[4] === 'undefined' ? 1 : +chunkHeader[4],\n      lines: [],\n      linedelimiters: []\n    }; // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n\n    if (hunk.oldLines === 0) {\n      hunk.oldStart += 1;\n    }\n\n    if (hunk.newLines === 0) {\n      hunk.newStart += 1;\n    }\n\n    var addCount = 0,\n        removeCount = 0;\n\n    for (; i < diffstr.length; i++) {\n      // Lines starting with '---' could be mistaken for the \"remove line\" operation\n      // But they could be the header for the next file. Therefore prune such cases out.\n      if (diffstr[i].indexOf('--- ') === 0 && i + 2 < diffstr.length && diffstr[i + 1].indexOf('+++ ') === 0 && diffstr[i + 2].indexOf('@@') === 0) {\n        break;\n      }\n\n      var operation = diffstr[i].length == 0 && i != diffstr.length - 1 ? ' ' : diffstr[i][0];\n\n      if (operation === '+' || operation === '-' || operation === ' ' || operation === '\\\\') {\n        hunk.lines.push(diffstr[i]);\n        hunk.linedelimiters.push(delimiters[i] || '\\n');\n\n        if (operation === '+') {\n          addCount++;\n        } else if (operation === '-') {\n          removeCount++;\n        } else if (operation === ' ') {\n          addCount++;\n          removeCount++;\n        }\n      } else {\n        break;\n      }\n    } // Handle the empty block count case\n\n\n    if (!addCount && hunk.newLines === 1) {\n      hunk.newLines = 0;\n    }\n\n    if (!removeCount && hunk.oldLines === 1) {\n      hunk.oldLines = 0;\n    } // Perform optional sanity checking\n\n\n    if (options.strict) {\n      if (addCount !== hunk.newLines) {\n        throw new Error('Added line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n      }\n\n      if (removeCount !== hunk.oldLines) {\n        throw new Error('Removed line count did not match for hunk at line ' + (chunkHeaderIndex + 1));\n      }\n    }\n\n    return hunk;\n  }\n\n  while (i < diffstr.length) {\n    parseIndex();\n  }\n\n  return list;\n}\n\n// Iterator that traverses in the range of [min, max], stepping\n// by distance from a given start position. I.e. for [0, 4], with\n// start of 2, this will iterate 2, 3, 1, 4, 0.\nfunction distanceIterator (start, minLine, maxLine) {\n  var wantForward = true,\n      backwardExhausted = false,\n      forwardExhausted = false,\n      localOffset = 1;\n  return function iterator() {\n    if (wantForward && !forwardExhausted) {\n      if (backwardExhausted) {\n        localOffset++;\n      } else {\n        wantForward = false;\n      } // Check if trying to fit beyond text length, and if not, check it fits\n      // after offset location (or desired location on first iteration)\n\n\n      if (start + localOffset <= maxLine) {\n        return localOffset;\n      }\n\n      forwardExhausted = true;\n    }\n\n    if (!backwardExhausted) {\n      if (!forwardExhausted) {\n        wantForward = true;\n      } // Check if trying to fit before text beginning, and if not, check it fits\n      // before offset location\n\n\n      if (minLine <= start - localOffset) {\n        return -localOffset++;\n      }\n\n      backwardExhausted = true;\n      return iterator();\n    } // We tried to fit hunk before text beginning and beyond text length, then\n    // hunk can't fit on the text. Return undefined\n\n  };\n}\n\nfunction applyPatch(source, uniDiff) {\n  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  if (Array.isArray(uniDiff)) {\n    if (uniDiff.length > 1) {\n      throw new Error('applyPatch only works with a single input.');\n    }\n\n    uniDiff = uniDiff[0];\n  } // Apply the diff to the input\n\n\n  var lines = source.split(/\\r\\n|[\\n\\v\\f\\r\\x85]/),\n      delimiters = source.match(/\\r\\n|[\\n\\v\\f\\r\\x85]/g) || [],\n      hunks = uniDiff.hunks,\n      compareLine = options.compareLine || function (lineNumber, line, operation, patchContent) {\n    return line === patchContent;\n  },\n      errorCount = 0,\n      fuzzFactor = options.fuzzFactor || 0,\n      minLine = 0,\n      offset = 0,\n      removeEOFNL,\n      addEOFNL;\n  /**\n   * Checks if the hunk exactly fits on the provided location\n   */\n\n\n  function hunkFits(hunk, toPos) {\n    for (var j = 0; j < hunk.lines.length; j++) {\n      var line = hunk.lines[j],\n          operation = line.length > 0 ? line[0] : ' ',\n          content = line.length > 0 ? line.substr(1) : line;\n\n      if (operation === ' ' || operation === '-') {\n        // Context sanity check\n        if (!compareLine(toPos + 1, lines[toPos], operation, content)) {\n          errorCount++;\n\n          if (errorCount > fuzzFactor) {\n            return false;\n          }\n        }\n\n        toPos++;\n      }\n    }\n\n    return true;\n  } // Search best fit offsets for each hunk based on the previous ones\n\n\n  for (var i = 0; i < hunks.length; i++) {\n    var hunk = hunks[i],\n        maxLine = lines.length - hunk.oldLines,\n        localOffset = 0,\n        toPos = offset + hunk.oldStart - 1;\n    var iterator = distanceIterator(toPos, minLine, maxLine);\n\n    for (; localOffset !== undefined; localOffset = iterator()) {\n      if (hunkFits(hunk, toPos + localOffset)) {\n        hunk.offset = offset += localOffset;\n        break;\n      }\n    }\n\n    if (localOffset === undefined) {\n      return false;\n    } // Set lower text limit to end of the current hunk, so next ones don't try\n    // to fit over already patched text\n\n\n    minLine = hunk.offset + hunk.oldStart + hunk.oldLines;\n  } // Apply patch hunks\n\n\n  var diffOffset = 0;\n\n  for (var _i = 0; _i < hunks.length; _i++) {\n    var _hunk = hunks[_i],\n        _toPos = _hunk.oldStart + _hunk.offset + diffOffset - 1;\n\n    diffOffset += _hunk.newLines - _hunk.oldLines;\n\n    for (var j = 0; j < _hunk.lines.length; j++) {\n      var line = _hunk.lines[j],\n          operation = line.length > 0 ? line[0] : ' ',\n          content = line.length > 0 ? line.substr(1) : line,\n          delimiter = _hunk.linedelimiters && _hunk.linedelimiters[j] || '\\n';\n\n      if (operation === ' ') {\n        _toPos++;\n      } else if (operation === '-') {\n        lines.splice(_toPos, 1);\n        delimiters.splice(_toPos, 1);\n        /* istanbul ignore else */\n      } else if (operation === '+') {\n        lines.splice(_toPos, 0, content);\n        delimiters.splice(_toPos, 0, delimiter);\n        _toPos++;\n      } else if (operation === '\\\\') {\n        var previousOperation = _hunk.lines[j - 1] ? _hunk.lines[j - 1][0] : null;\n\n        if (previousOperation === '+') {\n          removeEOFNL = true;\n        } else if (previousOperation === '-') {\n          addEOFNL = true;\n        }\n      }\n    }\n  } // Handle EOFNL insertion/removal\n\n\n  if (removeEOFNL) {\n    while (!lines[lines.length - 1]) {\n      lines.pop();\n      delimiters.pop();\n    }\n  } else if (addEOFNL) {\n    lines.push('');\n    delimiters.push('\\n');\n  }\n\n  for (var _k = 0; _k < lines.length - 1; _k++) {\n    lines[_k] = lines[_k] + delimiters[_k];\n  }\n\n  return lines.join('');\n} // Wrapper that supports multiple file patches via callbacks.\n\nfunction applyPatches(uniDiff, options) {\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  var currentIndex = 0;\n\n  function processIndex() {\n    var index = uniDiff[currentIndex++];\n\n    if (!index) {\n      return options.complete();\n    }\n\n    options.loadFile(index, function (err, data) {\n      if (err) {\n        return options.complete(err);\n      }\n\n      var updatedContent = applyPatch(data, index, options);\n      options.patched(index, updatedContent, function (err) {\n        if (err) {\n          return options.complete(err);\n        }\n\n        processIndex();\n      });\n    });\n  }\n\n  processIndex();\n}\n\nfunction structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  if (!options) {\n    options = {};\n  }\n\n  if (typeof options.context === 'undefined') {\n    options.context = 4;\n  }\n\n  var diff = diffLines(oldStr, newStr, options);\n\n  if (!diff) {\n    return;\n  }\n\n  diff.push({\n    value: '',\n    lines: []\n  }); // Append an empty value to make cleanup easier\n\n  function contextLines(lines) {\n    return lines.map(function (entry) {\n      return ' ' + entry;\n    });\n  }\n\n  var hunks = [];\n  var oldRangeStart = 0,\n      newRangeStart = 0,\n      curRange = [],\n      oldLine = 1,\n      newLine = 1;\n\n  var _loop = function _loop(i) {\n    var current = diff[i],\n        lines = current.lines || current.value.replace(/\\n$/, '').split('\\n');\n    current.lines = lines;\n\n    if (current.added || current.removed) {\n      var _curRange;\n\n      // If we have previous context, start with that\n      if (!oldRangeStart) {\n        var prev = diff[i - 1];\n        oldRangeStart = oldLine;\n        newRangeStart = newLine;\n\n        if (prev) {\n          curRange = options.context > 0 ? contextLines(prev.lines.slice(-options.context)) : [];\n          oldRangeStart -= curRange.length;\n          newRangeStart -= curRange.length;\n        }\n      } // Output our changes\n\n\n      (_curRange = curRange).push.apply(_curRange, _toConsumableArray(lines.map(function (entry) {\n        return (current.added ? '+' : '-') + entry;\n      }))); // Track the updated file position\n\n\n      if (current.added) {\n        newLine += lines.length;\n      } else {\n        oldLine += lines.length;\n      }\n    } else {\n      // Identical context lines. Track line changes\n      if (oldRangeStart) {\n        // Close out any changes that have been output (or join overlapping)\n        if (lines.length <= options.context * 2 && i < diff.length - 2) {\n          var _curRange2;\n\n          // Overlapping\n          (_curRange2 = curRange).push.apply(_curRange2, _toConsumableArray(contextLines(lines)));\n        } else {\n          var _curRange3;\n\n          // end the range and output\n          var contextSize = Math.min(lines.length, options.context);\n\n          (_curRange3 = curRange).push.apply(_curRange3, _toConsumableArray(contextLines(lines.slice(0, contextSize))));\n\n          var hunk = {\n            oldStart: oldRangeStart,\n            oldLines: oldLine - oldRangeStart + contextSize,\n            newStart: newRangeStart,\n            newLines: newLine - newRangeStart + contextSize,\n            lines: curRange\n          };\n\n          if (i >= diff.length - 2 && lines.length <= options.context) {\n            // EOF is inside this hunk\n            var oldEOFNewline = /\\n$/.test(oldStr);\n            var newEOFNewline = /\\n$/.test(newStr);\n            var noNlBeforeAdds = lines.length == 0 && curRange.length > hunk.oldLines;\n\n            if (!oldEOFNewline && noNlBeforeAdds && oldStr.length > 0) {\n              // special case: old has no eol and no trailing context; no-nl can end up before adds\n              // however, if the old file is empty, do not output the no-nl line\n              curRange.splice(hunk.oldLines, 0, '\\\\ No newline at end of file');\n            }\n\n            if (!oldEOFNewline && !noNlBeforeAdds || !newEOFNewline) {\n              curRange.push('\\\\ No newline at end of file');\n            }\n          }\n\n          hunks.push(hunk);\n          oldRangeStart = 0;\n          newRangeStart = 0;\n          curRange = [];\n        }\n      }\n\n      oldLine += lines.length;\n      newLine += lines.length;\n    }\n  };\n\n  for (var i = 0; i < diff.length; i++) {\n    _loop(i);\n  }\n\n  return {\n    oldFileName: oldFileName,\n    newFileName: newFileName,\n    oldHeader: oldHeader,\n    newHeader: newHeader,\n    hunks: hunks\n  };\n}\nfunction formatPatch(diff) {\n  if (Array.isArray(diff)) {\n    return diff.map(formatPatch).join('\\n');\n  }\n\n  var ret = [];\n\n  if (diff.oldFileName == diff.newFileName) {\n    ret.push('Index: ' + diff.oldFileName);\n  }\n\n  ret.push('===================================================================');\n  ret.push('--- ' + diff.oldFileName + (typeof diff.oldHeader === 'undefined' ? '' : '\\t' + diff.oldHeader));\n  ret.push('+++ ' + diff.newFileName + (typeof diff.newHeader === 'undefined' ? '' : '\\t' + diff.newHeader));\n\n  for (var i = 0; i < diff.hunks.length; i++) {\n    var hunk = diff.hunks[i]; // Unified Diff Format quirk: If the chunk size is 0,\n    // the first number is one lower than one would expect.\n    // https://www.artima.com/weblogs/viewpost.jsp?thread=164293\n\n    if (hunk.oldLines === 0) {\n      hunk.oldStart -= 1;\n    }\n\n    if (hunk.newLines === 0) {\n      hunk.newStart -= 1;\n    }\n\n    ret.push('@@ -' + hunk.oldStart + ',' + hunk.oldLines + ' +' + hunk.newStart + ',' + hunk.newLines + ' @@');\n    ret.push.apply(ret, hunk.lines);\n  }\n\n  return ret.join('\\n') + '\\n';\n}\nfunction createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) {\n  return formatPatch(structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options));\n}\nfunction createPatch(fileName, oldStr, newStr, oldHeader, newHeader, options) {\n  return createTwoFilesPatch(fileName, fileName, oldStr, newStr, oldHeader, newHeader, options);\n}\n\nfunction arrayEqual(a, b) {\n  if (a.length !== b.length) {\n    return false;\n  }\n\n  return arrayStartsWith(a, b);\n}\nfunction arrayStartsWith(array, start) {\n  if (start.length > array.length) {\n    return false;\n  }\n\n  for (var i = 0; i < start.length; i++) {\n    if (start[i] !== array[i]) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction calcLineCount(hunk) {\n  var _calcOldNewLineCount = calcOldNewLineCount(hunk.lines),\n      oldLines = _calcOldNewLineCount.oldLines,\n      newLines = _calcOldNewLineCount.newLines;\n\n  if (oldLines !== undefined) {\n    hunk.oldLines = oldLines;\n  } else {\n    delete hunk.oldLines;\n  }\n\n  if (newLines !== undefined) {\n    hunk.newLines = newLines;\n  } else {\n    delete hunk.newLines;\n  }\n}\nfunction merge(mine, theirs, base) {\n  mine = loadPatch(mine, base);\n  theirs = loadPatch(theirs, base);\n  var ret = {}; // For index we just let it pass through as it doesn't have any necessary meaning.\n  // Leaving sanity checks on this to the API consumer that may know more about the\n  // meaning in their own context.\n\n  if (mine.index || theirs.index) {\n    ret.index = mine.index || theirs.index;\n  }\n\n  if (mine.newFileName || theirs.newFileName) {\n    if (!fileNameChanged(mine)) {\n      // No header or no change in ours, use theirs (and ours if theirs does not exist)\n      ret.oldFileName = theirs.oldFileName || mine.oldFileName;\n      ret.newFileName = theirs.newFileName || mine.newFileName;\n      ret.oldHeader = theirs.oldHeader || mine.oldHeader;\n      ret.newHeader = theirs.newHeader || mine.newHeader;\n    } else if (!fileNameChanged(theirs)) {\n      // No header or no change in theirs, use ours\n      ret.oldFileName = mine.oldFileName;\n      ret.newFileName = mine.newFileName;\n      ret.oldHeader = mine.oldHeader;\n      ret.newHeader = mine.newHeader;\n    } else {\n      // Both changed... figure it out\n      ret.oldFileName = selectField(ret, mine.oldFileName, theirs.oldFileName);\n      ret.newFileName = selectField(ret, mine.newFileName, theirs.newFileName);\n      ret.oldHeader = selectField(ret, mine.oldHeader, theirs.oldHeader);\n      ret.newHeader = selectField(ret, mine.newHeader, theirs.newHeader);\n    }\n  }\n\n  ret.hunks = [];\n  var mineIndex = 0,\n      theirsIndex = 0,\n      mineOffset = 0,\n      theirsOffset = 0;\n\n  while (mineIndex < mine.hunks.length || theirsIndex < theirs.hunks.length) {\n    var mineCurrent = mine.hunks[mineIndex] || {\n      oldStart: Infinity\n    },\n        theirsCurrent = theirs.hunks[theirsIndex] || {\n      oldStart: Infinity\n    };\n\n    if (hunkBefore(mineCurrent, theirsCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(mineCurrent, mineOffset));\n      mineIndex++;\n      theirsOffset += mineCurrent.newLines - mineCurrent.oldLines;\n    } else if (hunkBefore(theirsCurrent, mineCurrent)) {\n      // This patch does not overlap with any of the others, yay.\n      ret.hunks.push(cloneHunk(theirsCurrent, theirsOffset));\n      theirsIndex++;\n      mineOffset += theirsCurrent.newLines - theirsCurrent.oldLines;\n    } else {\n      // Overlap, merge as best we can\n      var mergedHunk = {\n        oldStart: Math.min(mineCurrent.oldStart, theirsCurrent.oldStart),\n        oldLines: 0,\n        newStart: Math.min(mineCurrent.newStart + mineOffset, theirsCurrent.oldStart + theirsOffset),\n        newLines: 0,\n        lines: []\n      };\n      mergeLines(mergedHunk, mineCurrent.oldStart, mineCurrent.lines, theirsCurrent.oldStart, theirsCurrent.lines);\n      theirsIndex++;\n      mineIndex++;\n      ret.hunks.push(mergedHunk);\n    }\n  }\n\n  return ret;\n}\n\nfunction loadPatch(param, base) {\n  if (typeof param === 'string') {\n    if (/^@@/m.test(param) || /^Index:/m.test(param)) {\n      return parsePatch(param)[0];\n    }\n\n    if (!base) {\n      throw new Error('Must provide a base reference or pass in a patch');\n    }\n\n    return structuredPatch(undefined, undefined, base, param);\n  }\n\n  return param;\n}\n\nfunction fileNameChanged(patch) {\n  return patch.newFileName && patch.newFileName !== patch.oldFileName;\n}\n\nfunction selectField(index, mine, theirs) {\n  if (mine === theirs) {\n    return mine;\n  } else {\n    index.conflict = true;\n    return {\n      mine: mine,\n      theirs: theirs\n    };\n  }\n}\n\nfunction hunkBefore(test, check) {\n  return test.oldStart < check.oldStart && test.oldStart + test.oldLines < check.oldStart;\n}\n\nfunction cloneHunk(hunk, offset) {\n  return {\n    oldStart: hunk.oldStart,\n    oldLines: hunk.oldLines,\n    newStart: hunk.newStart + offset,\n    newLines: hunk.newLines,\n    lines: hunk.lines\n  };\n}\n\nfunction mergeLines(hunk, mineOffset, mineLines, theirOffset, theirLines) {\n  // This will generally result in a conflicted hunk, but there are cases where the context\n  // is the only overlap where we can successfully merge the content here.\n  var mine = {\n    offset: mineOffset,\n    lines: mineLines,\n    index: 0\n  },\n      their = {\n    offset: theirOffset,\n    lines: theirLines,\n    index: 0\n  }; // Handle any leading content\n\n  insertLeading(hunk, mine, their);\n  insertLeading(hunk, their, mine); // Now in the overlap content. Scan through and select the best changes from each.\n\n  while (mine.index < mine.lines.length && their.index < their.lines.length) {\n    var mineCurrent = mine.lines[mine.index],\n        theirCurrent = their.lines[their.index];\n\n    if ((mineCurrent[0] === '-' || mineCurrent[0] === '+') && (theirCurrent[0] === '-' || theirCurrent[0] === '+')) {\n      // Both modified ...\n      mutualChange(hunk, mine, their);\n    } else if (mineCurrent[0] === '+' && theirCurrent[0] === ' ') {\n      var _hunk$lines;\n\n      // Mine inserted\n      (_hunk$lines = hunk.lines).push.apply(_hunk$lines, _toConsumableArray(collectChange(mine)));\n    } else if (theirCurrent[0] === '+' && mineCurrent[0] === ' ') {\n      var _hunk$lines2;\n\n      // Theirs inserted\n      (_hunk$lines2 = hunk.lines).push.apply(_hunk$lines2, _toConsumableArray(collectChange(their)));\n    } else if (mineCurrent[0] === '-' && theirCurrent[0] === ' ') {\n      // Mine removed or edited\n      removal(hunk, mine, their);\n    } else if (theirCurrent[0] === '-' && mineCurrent[0] === ' ') {\n      // Their removed or edited\n      removal(hunk, their, mine, true);\n    } else if (mineCurrent === theirCurrent) {\n      // Context identity\n      hunk.lines.push(mineCurrent);\n      mine.index++;\n      their.index++;\n    } else {\n      // Context mismatch\n      conflict(hunk, collectChange(mine), collectChange(their));\n    }\n  } // Now push anything that may be remaining\n\n\n  insertTrailing(hunk, mine);\n  insertTrailing(hunk, their);\n  calcLineCount(hunk);\n}\n\nfunction mutualChange(hunk, mine, their) {\n  var myChanges = collectChange(mine),\n      theirChanges = collectChange(their);\n\n  if (allRemoves(myChanges) && allRemoves(theirChanges)) {\n    // Special case for remove changes that are supersets of one another\n    if (arrayStartsWith(myChanges, theirChanges) && skipRemoveSuperset(their, myChanges, myChanges.length - theirChanges.length)) {\n      var _hunk$lines3;\n\n      (_hunk$lines3 = hunk.lines).push.apply(_hunk$lines3, _toConsumableArray(myChanges));\n\n      return;\n    } else if (arrayStartsWith(theirChanges, myChanges) && skipRemoveSuperset(mine, theirChanges, theirChanges.length - myChanges.length)) {\n      var _hunk$lines4;\n\n      (_hunk$lines4 = hunk.lines).push.apply(_hunk$lines4, _toConsumableArray(theirChanges));\n\n      return;\n    }\n  } else if (arrayEqual(myChanges, theirChanges)) {\n    var _hunk$lines5;\n\n    (_hunk$lines5 = hunk.lines).push.apply(_hunk$lines5, _toConsumableArray(myChanges));\n\n    return;\n  }\n\n  conflict(hunk, myChanges, theirChanges);\n}\n\nfunction removal(hunk, mine, their, swap) {\n  var myChanges = collectChange(mine),\n      theirChanges = collectContext(their, myChanges);\n\n  if (theirChanges.merged) {\n    var _hunk$lines6;\n\n    (_hunk$lines6 = hunk.lines).push.apply(_hunk$lines6, _toConsumableArray(theirChanges.merged));\n  } else {\n    conflict(hunk, swap ? theirChanges : myChanges, swap ? myChanges : theirChanges);\n  }\n}\n\nfunction conflict(hunk, mine, their) {\n  hunk.conflict = true;\n  hunk.lines.push({\n    conflict: true,\n    mine: mine,\n    theirs: their\n  });\n}\n\nfunction insertLeading(hunk, insert, their) {\n  while (insert.offset < their.offset && insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n    insert.offset++;\n  }\n}\n\nfunction insertTrailing(hunk, insert) {\n  while (insert.index < insert.lines.length) {\n    var line = insert.lines[insert.index++];\n    hunk.lines.push(line);\n  }\n}\n\nfunction collectChange(state) {\n  var ret = [],\n      operation = state.lines[state.index][0];\n\n  while (state.index < state.lines.length) {\n    var line = state.lines[state.index]; // Group additions that are immediately after subtractions and treat them as one \"atomic\" modify change.\n\n    if (operation === '-' && line[0] === '+') {\n      operation = '+';\n    }\n\n    if (operation === line[0]) {\n      ret.push(line);\n      state.index++;\n    } else {\n      break;\n    }\n  }\n\n  return ret;\n}\n\nfunction collectContext(state, matchChanges) {\n  var changes = [],\n      merged = [],\n      matchIndex = 0,\n      contextChanges = false,\n      conflicted = false;\n\n  while (matchIndex < matchChanges.length && state.index < state.lines.length) {\n    var change = state.lines[state.index],\n        match = matchChanges[matchIndex]; // Once we've hit our add, then we are done\n\n    if (match[0] === '+') {\n      break;\n    }\n\n    contextChanges = contextChanges || change[0] !== ' ';\n    merged.push(match);\n    matchIndex++; // Consume any additions in the other block as a conflict to attempt\n    // to pull in the remaining context after this\n\n    if (change[0] === '+') {\n      conflicted = true;\n\n      while (change[0] === '+') {\n        changes.push(change);\n        change = state.lines[++state.index];\n      }\n    }\n\n    if (match.substr(1) === change.substr(1)) {\n      changes.push(change);\n      state.index++;\n    } else {\n      conflicted = true;\n    }\n  }\n\n  if ((matchChanges[matchIndex] || '')[0] === '+' && contextChanges) {\n    conflicted = true;\n  }\n\n  if (conflicted) {\n    return changes;\n  }\n\n  while (matchIndex < matchChanges.length) {\n    merged.push(matchChanges[matchIndex++]);\n  }\n\n  return {\n    merged: merged,\n    changes: changes\n  };\n}\n\nfunction allRemoves(changes) {\n  return changes.reduce(function (prev, change) {\n    return prev && change[0] === '-';\n  }, true);\n}\n\nfunction skipRemoveSuperset(state, removeChanges, delta) {\n  for (var i = 0; i < delta; i++) {\n    var changeContent = removeChanges[removeChanges.length - delta + i].substr(1);\n\n    if (state.lines[state.index + i] !== ' ' + changeContent) {\n      return false;\n    }\n  }\n\n  state.index += delta;\n  return true;\n}\n\nfunction calcOldNewLineCount(lines) {\n  var oldLines = 0;\n  var newLines = 0;\n  lines.forEach(function (line) {\n    if (typeof line !== 'string') {\n      var myCount = calcOldNewLineCount(line.mine);\n      var theirCount = calcOldNewLineCount(line.theirs);\n\n      if (oldLines !== undefined) {\n        if (myCount.oldLines === theirCount.oldLines) {\n          oldLines += myCount.oldLines;\n        } else {\n          oldLines = undefined;\n        }\n      }\n\n      if (newLines !== undefined) {\n        if (myCount.newLines === theirCount.newLines) {\n          newLines += myCount.newLines;\n        } else {\n          newLines = undefined;\n        }\n      }\n    } else {\n      if (newLines !== undefined && (line[0] === '+' || line[0] === ' ')) {\n        newLines++;\n      }\n\n      if (oldLines !== undefined && (line[0] === '-' || line[0] === ' ')) {\n        oldLines++;\n      }\n    }\n  });\n  return {\n    oldLines: oldLines,\n    newLines: newLines\n  };\n}\n\nfunction reversePatch(structuredPatch) {\n  if (Array.isArray(structuredPatch)) {\n    return structuredPatch.map(reversePatch).reverse();\n  }\n\n  return _objectSpread2(_objectSpread2({}, structuredPatch), {}, {\n    oldFileName: structuredPatch.newFileName,\n    oldHeader: structuredPatch.newHeader,\n    newFileName: structuredPatch.oldFileName,\n    newHeader: structuredPatch.oldHeader,\n    hunks: structuredPatch.hunks.map(function (hunk) {\n      return {\n        oldLines: hunk.newLines,\n        oldStart: hunk.newStart,\n        newLines: hunk.oldLines,\n        newStart: hunk.oldStart,\n        linedelimiters: hunk.linedelimiters,\n        lines: hunk.lines.map(function (l) {\n          if (l.startsWith('-')) {\n            return \"+\".concat(l.slice(1));\n          }\n\n          if (l.startsWith('+')) {\n            return \"-\".concat(l.slice(1));\n          }\n\n          return l;\n        })\n      };\n    })\n  });\n}\n\n// See: http://code.google.com/p/google-diff-match-patch/wiki/API\nfunction convertChangesToDMP(changes) {\n  var ret = [],\n      change,\n      operation;\n\n  for (var i = 0; i < changes.length; i++) {\n    change = changes[i];\n\n    if (change.added) {\n      operation = 1;\n    } else if (change.removed) {\n      operation = -1;\n    } else {\n      operation = 0;\n    }\n\n    ret.push([operation, change.value]);\n  }\n\n  return ret;\n}\n\nfunction convertChangesToXML(changes) {\n  var ret = [];\n\n  for (var i = 0; i < changes.length; i++) {\n    var change = changes[i];\n\n    if (change.added) {\n      ret.push('<ins>');\n    } else if (change.removed) {\n      ret.push('<del>');\n    }\n\n    ret.push(escapeHTML(change.value));\n\n    if (change.added) {\n      ret.push('</ins>');\n    } else if (change.removed) {\n      ret.push('</del>');\n    }\n  }\n\n  return ret.join('');\n}\n\nfunction escapeHTML(s) {\n  var n = s;\n  n = n.replace(/&/g, '&amp;');\n  n = n.replace(/</g, '&lt;');\n  n = n.replace(/>/g, '&gt;');\n  n = n.replace(/\"/g, '&quot;');\n  return n;\n}\n\nexport { Diff, applyPatch, applyPatches, canonicalize, convertChangesToDMP, convertChangesToXML, createPatch, createTwoFilesPatch, diffArrays, diffChars, diffCss, diffJson, diffLines, diffSentences, diffTrimmedLines, diffWords, diffWordsWithSpace, formatPatch, merge, parsePatch, reversePatch, structuredPatch };\n", "import { diffChars } from \"diff\";\nimport { TextQuoteSelector } from \"text-quote-selector\";\n\nexport type Annolink = Pick<Annopage, \"projectName\" | \"title\">;\n\nexport interface Annopage {\n  projectName: string;\n  title: string;\n  configs: {\n    textQuoteSelector: TextQuoteSelector;\n    markerText: string;\n    lineID: string;\n    description: string;\n    icons: {\n      url: string;\n      isStrong: boolean;\n    }[];\n  }[];\n}\n\ninterface Project {\n  name: string;\n  image?: string;\n}\n\nconst annoProtocolMap = new Map([\n  [\"http:\", \"anno:\"],\n  [\"https:\", \"annos:\"],\n]);\nconst fallbackIconURL =\n  \"https://i.gyazo.com/1e3dbb79088aa1627d7e092481848df5.png\";\n\nexport const clearScrapboxLoaderCache = () => {\n  projectCache.clear();\n};\n\nexport const extractAnnolink = (url: string) => {\n  const annolinkPaths = getAnnolink(url).split(\"/\");\n  const annolinks = [];\n  do {\n    annolinks.unshift(decodeURI(annolinkPaths.join(\"/\")));\n    annolinkPaths.pop();\n  } while (annolinkPaths.length >= 2);\n  return annolinks;\n};\n\nexport const fetchAnnopages = async ({\n  annoProjectName,\n  annolink,\n  fetcher,\n}: {\n  annoProjectName: string;\n  annolink: string;\n  fetcher: typeof fetch;\n}) => {\n  const annopageEntries: [string, Annopage][] = [];\n\n  const annolinkPageResponse = await fetcher(\n    `https://scrapbox.io/api/pages/${encodeURIComponent(\n      annoProjectName\n    )}/${encodeURIComponent(annolink)}`\n  );\n  if (!annolinkPageResponse.ok) {\n    console.error(`Failed to fetch page: ${annolinkPageResponse.status}`);\n    return annopageEntries;\n  }\n  const annolinkPage = await annolinkPageResponse.json();\n\n  const annolinkPageText = annolinkPage.lines\n    // @ts-expect-error\n    .map(({ text }) => text)\n    .join(\"\\n\");\n  const annopageLinks: Annolink[] = [\n    ...new Set(\n      [\n        ...annolinkPage.links,\n        ...annolinkPage.projectLinks,\n        // @ts-expect-error\n        ...annolinkPage.relatedPages.links1hop.map(({ title }) => title),\n      ].sort(\n        (a, b) =>\n          annolinkPageText.indexOf(`[${b}]`) -\n          annolinkPageText.indexOf(`[${a}]`)\n      )\n    ),\n  ].map((link) => {\n    const paths = link.split(\"/\");\n    return link.startsWith(\"/\")\n      ? { projectName: paths[1], title: paths.slice(2).join(\"/\") }\n      : { projectName: annoProjectName, title: link };\n  });\n\n  for (const annopageLink of annopageLinks) {\n    const annopageEntry = await fetchAnnopage({ annopageLink, fetcher });\n    if (!annopageEntry) {\n      continue;\n    }\n    annopageEntries.push(annopageEntry);\n  }\n\n  return annopageEntries;\n};\n\nexport const getAnnolink = (url: string) => {\n  let replacedURL = url;\n  for (const [protocol, annoProtocol] of annoProtocolMap) {\n    if (replacedURL.startsWith(protocol)) {\n      replacedURL = replacedURL.replace(protocol, annoProtocol);\n    }\n  }\n  return replacedURL;\n};\n\nexport const isAnnolink = (url: string) =>\n  [...annoProtocolMap].some(([, annoProtocol]) => url.startsWith(annoProtocol));\n\nconst projectCache = new Map<string, Promise<Project | undefined>>();\n\nconst fetchAnnopage = async ({\n  annopageLink,\n  fetcher,\n}: {\n  annopageLink: Annolink;\n  fetcher: typeof fetch;\n}): Promise<[string, Annopage] | undefined> => {\n  const annopageProjectPromise =\n    projectCache.get(annopageLink.projectName) ??\n    (async (): Promise<Project | undefined> => {\n      const projectAPIResponse = await fetcher(\n        `https://scrapbox.io/api/projects/${encodeURIComponent(\n          annopageLink.projectName\n        )}`\n      );\n      if (!projectAPIResponse.ok) {\n        console.error(`Failed to fetch project: ${projectAPIResponse.status}`);\n        return;\n      }\n      return projectAPIResponse.json();\n    })();\n  projectCache.set(annopageLink.projectName, annopageProjectPromise);\n  const annopageProject = await annopageProjectPromise;\n  if (!annopageProject) {\n    return;\n  }\n\n  const annopageResponse = await fetcher(\n    `https://scrapbox.io/api/pages/${encodeURIComponent(\n      annopageProject.name\n    )}/${encodeURIComponent(annopageLink.title)}?followRename`\n  );\n  if (!annopageResponse.ok) {\n    console.error(`Failed to fetch page: ${annopageResponse.status}`);\n    return;\n  }\n  const annopage = await annopageResponse.json();\n\n  const sections = [];\n  let section = [];\n  for (const line of annopage.lines.slice(1)) {\n    if (line.text) {\n      section.push(line);\n    } else {\n      sections.push(section);\n      section = [];\n    }\n  }\n  sections.push(section);\n\n  const configs = [];\n  for (const section of sections) {\n    const sectionText = section.map(({ text }) => text).join(\"\\n\");\n\n    const annotations = [\n      ...sectionText.matchAll(/\\[([^\\]]*)\\s(.*?)\\]/g),\n    ].flatMap((linkExpressionMatch) => {\n      let searchParams;\n      try {\n        searchParams = new URLSearchParams(\n          new URL(linkExpressionMatch[2]).hash.slice(1)\n        );\n      } catch {\n        return [];\n      }\n\n      const exact = searchParams.get(\"e\");\n      if (!exact) {\n        return [];\n      }\n\n      return [\n        {\n          body: linkExpressionMatch[0],\n          prefix: searchParams.get(\"p\") ?? undefined,\n          exact,\n          suffix: searchParams.get(\"s\") ?? undefined,\n          markerText: linkExpressionMatch[1],\n        },\n      ];\n    });\n\n    let annotationRemovedText = sectionText;\n    for (const { body } of annotations) {\n      annotationRemovedText = annotationRemovedText.replaceAll(body, \"\");\n    }\n    const annotationRemovedLines = annotationRemovedText.trim().split(\"\\n\");\n    const mod = annotationRemovedLines\n      .flatMap((line) => {\n        const match = line.match(/^\\s*>(.*)/);\n        return match ? [match[1].trim()] : [];\n      })\n      .join(\"\\n\");\n    const description = annotationRemovedLines\n      .filter((line) => !line.trim().startsWith(\">\"))\n      .join(\"\\n\");\n\n    const icons = [];\n    for (const iconExpressionMatch of sectionText.matchAll(\n      /(\\[?)\\[([^\\]]+)\\.icon(?:\\*([1-9]\\d*))?\\](\\]?)/g\n    )) {\n      const title = iconExpressionMatch[2];\n      const tower = Number(iconExpressionMatch[3] ?? \"1\");\n      const isStrong = Boolean(\n        iconExpressionMatch[1] && iconExpressionMatch[4]\n      );\n\n      for (const _towerIndex of Array(tower).keys()) {\n        icons.push({\n          url: `https://scrapbox.io/api/pages/${encodeURIComponent(\n            annopageProject.name\n          )}/${encodeURIComponent(title)}/icon?followRename`,\n          isStrong,\n        });\n      }\n    }\n    if (icons.length < 1) {\n      icons.push({\n        url: annopageProject.image ?? fallbackIconURL,\n        isStrong: false,\n      });\n    }\n\n    for (const { prefix, exact, suffix, markerText } of annotations) {\n      configs.push({\n        textQuoteSelector: { prefix, exact, suffix },\n        diff: diffChars(exact, mod),\n        markerText,\n        lineID: section[0].id,\n        description,\n        icons,\n      });\n    }\n  }\n\n  return [\n    annopage.id,\n    {\n      projectName: annopageProject.name,\n      title: annopage.title,\n      configs,\n    },\n  ];\n};\n", "import { browser } from \"./browser-polyfill\";\nimport type { ExternalMessage } from \"./types/messages\";\nimport { encodeForScrapboxReadableLink } from \"./url\";\n\nimport { isAnnolink } from \"scrapbox-loader\";\n\nconst EXTENSION_ID = process.env.EXTENSION_ID;\nif (!EXTENSION_ID) {\n  throw new Error(\"EXTENSION_ID is not defined\");\n}\n\nconst annoImageURL = \"https://i.gyazo.com/1e3dbb79088aa1627d7e092481848df5.png\";\nconst collaborateMenuTitle = \"Collaborate with anno\";\n// @ts-expect-error\nscrapbox.PageMenu.addMenu({\n  title: collaborateMenuTitle,\n  image: annoImageURL,\n  onClick: () => {\n    if (!collaborateMessage) {\n      return;\n    }\n\n    browser.runtime.sendMessage(EXTENSION_ID, collaborateMessage);\n  },\n});\nconst disabledCollaborateMenuTitle =\n  \"Can't Collaborate with anno because this Scrapbox page has no annolinks. \";\n// @ts-expect-error\nscrapbox.PageMenu.addMenu({\n  title: disabledCollaborateMenuTitle,\n  image: annoImageURL,\n  onClick: () => {\n    open(\n      \"https://scrapbox.io/hata6502/Can't_Collaborate_with_anno_because_this_Scrapbox_page_has_no_annolinks\"\n    );\n  },\n});\n\nconst markWordMenuTitle = \"Mark word by anno\";\n// @ts-expect-error\nscrapbox.PageMenu.addMenu({\n  title: markWordMenuTitle,\n  image: \"https://i.gyazo.com/2e9dc1b43de352164a90a6d284ce0175.png\",\n  onClick: () => {\n    const word = prompt(\"Word\");\n    if (!word) {\n      return;\n    }\n\n    location.search = `?${new URLSearchParams({\n      body: `[\uD83C\uDF40 https://scrapbox.io/hata6502/anno_word_marker#e=${encodeForScrapboxReadableLink(\n        word\n      )}]\n${word\n  .split(\"\\n\")\n  .map((line) => `> ${line}`)\n  .join(\"\\n\")}`,\n    })}`;\n  },\n});\n\nconst styleElement = document.createElement(\"style\");\ndocument.head.append(styleElement);\nconst setStyle = ({ isCollaboratable }: { isCollaboratable: boolean }) => {\n  styleElement.textContent = `\n    #${CSS.escape(collaborateMenuTitle)} {\n      ${isCollaboratable ? \"\" : \"display: none;\"}\n    }\n\n    #${CSS.escape(disabledCollaborateMenuTitle)} {\n      filter: saturate(0%);\n      ${isCollaboratable ? \"display: none;\" : \"\"}\n    }\n\n    #${CSS.escape(markWordMenuTitle)} {\n      ${isCollaboratable ? \"\" : \"display: none;\"}\n    }\n  `;\n};\nsetStyle({ isCollaboratable: false });\n\nlet collaborateMessage: ExternalMessage | undefined;\nconst checkCollaboratable = async () => {\n  // @ts-expect-error\n  const pageTitle = scrapbox.Page.title;\n  if (!pageTitle) {\n    return;\n  }\n\n  const annolinks: string[] = [];\n  JSON.stringify(\n    // @ts-expect-error\n    scrapbox.Page.lines,\n    (_key, value: unknown) => {\n      const annolink = extractAnnolink(value);\n      if (annolink) {\n        annolinks.push(annolink);\n      }\n\n      return value;\n    }\n  );\n  const uniqueAnnolinks = [...new Set(annolinks)];\n\n  collaborateMessage = {\n    type: \"collaborate\",\n    // @ts-expect-error\n    projectName: scrapbox.Project.name,\n    pageTitle,\n    annolinks: uniqueAnnolinks,\n  };\n  setStyle({ isCollaboratable: Boolean(uniqueAnnolinks.length) });\n};\n\nconst extractAnnolink = (value: unknown) => {\n  if (typeof value !== \"object\" || value === null) {\n    return;\n  }\n\n  if (!(\"type\" in value) || value.type !== \"link\") {\n    return;\n  }\n  if (\n    !(\"unit\" in value) ||\n    typeof value.unit !== \"object\" ||\n    value.unit === null\n  ) {\n    return;\n  }\n  const { unit } = value;\n\n  if (\"project\" in unit) {\n    return;\n  }\n  if (!(\"page\" in unit) || typeof unit.page !== \"string\") {\n    return;\n  }\n  const { page } = unit;\n\n  if (!isAnnolink(page)) {\n    return;\n  }\n\n  return page;\n};\n\ncheckCollaboratable();\n// @ts-expect-error\nscrapbox.on(\"lines:changed\", checkCollaboratable);\n// @ts-expect-error\nscrapbox.on(\"page:changed\", checkCollaboratable);\n"],
  "mappings": ";AASO,IAAM,WAAW,MAAM;AAE5B,MAAI,OAAQ,WAAmB,YAAY,aAAa;AACtD,UAAM,MAAO,WAAmB;AAGhC,QAAI,YAAY,iCAAiC,KAAK,UAAU,SAAS;AACzE,QAAI,SAAS,mBAAmB,KAAK,UAAU,SAAS,KAAK,CAAE,OAAe;AAE9E,WAAO;AAAA,EACT;AAGA,MAAI,OAAQ,WAAmB,WAAW,eAAgB,WAAmB,OAAO,SAAS;AAC3F,UAAM,MAAO,WAAmB;AAGhC,QAAI,YAAY;AAChB,QAAI,SAAS;AAEb,WAAO;AAAA,EACT;AAGA,UAAQ,MAAM,iCAAiC;AAG/C,SAAO;AAAA,IACL,WAAW,iCAAiC,KAAK,UAAU,SAAS;AAAA,IACpE,QAAQ,mBAAmB,KAAK,UAAU,SAAS,KAAK,CAAE,OAAe;AAAA,IACzE,SAAS;AAAA,MACP,WAAW,EAAE,aAAa,MAAM;AAAA,MAAC,EAAE;AAAA,MACnC,aAAa,MAAM,QAAQ,QAAQ;AAAA,MACnC,QAAQ,CAAC,SAAiB;AAAA,IAC5B;AAAA,IACA,SAAS;AAAA,MACP,MAAM;AAAA,QACJ,KAAK,MAAM,QAAQ,QAAQ,CAAC,CAAC;AAAA,QAC7B,KAAK,MAAM,QAAQ,QAAQ;AAAA,MAC7B;AAAA,MACA,OAAO;AAAA,QACL,KAAK,MAAM,QAAQ,QAAQ,CAAC,CAAC;AAAA,QAC7B,KAAK,MAAM,QAAQ,QAAQ;AAAA,MAC7B;AAAA,IACF;AAAA,IACA,QAAQ;AAAA,MACN,WAAW,EAAE,aAAa,MAAM;AAAA,MAAC,EAAE;AAAA,IACrC;AAAA,IACA,MAAM;AAAA,MACJ,aAAa,MAAM,QAAQ,QAAQ;AAAA,MACnC,OAAO,MAAM,QAAQ,QAAQ,CAAC,CAAC;AAAA,IACjC;AAAA,EACF;AACF,GAAG;AAmFH,IAAI,OAAQ,WAAmB,YAAY,aAAa;AACtD,EAAC,WAAmB,UAAU;AAChC;AACA,IAAI,OAAQ,WAAmB,WAAW,aAAa;AACrD,EAAC,WAAmB,SAAS;AAC/B;;;ACtJO,IAAM,gCAAgC,CAAC,iBAAyB;AACrE,MAAI,UAAU,mBAAmB,YAAY;AAE7C,YAAU,QAAQ,WAAW,OAAO,GAAG;AAEvC,aAAW,SAAS,aAAa;AAAA,IAC/B;AAAA,EACF,GAAG;AACD,cAAU,QAAQ,QAAQ,mBAAmB,MAAM,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC;AAAA,EAClE;AAEA,SAAO;AACT;;;ACZA,SAAS,OAAO;AAAC;AACjB,KAAK,YAAY;AAAA,EACf,MAAM,SAAS,KAAK,WAAW,WAAW;AACxC,QAAI;AAEJ,QAAI,UAAU,UAAU,SAAS,KAAK,UAAU,CAAC,MAAM,SAAY,UAAU,CAAC,IAAI,CAAC;AACnF,QAAI,WAAW,QAAQ;AAEvB,QAAI,OAAO,YAAY,YAAY;AACjC,iBAAW;AACX,gBAAU,CAAC;AAAA,IACb;AAEA,SAAK,UAAU;AACf,QAAI,OAAO;AAEX,aAAS,KAAK,OAAO;AACnB,UAAI,UAAU;AACZ,mBAAW,WAAY;AACrB,mBAAS,QAAW,KAAK;AAAA,QAC3B,GAAG,CAAC;AACJ,eAAO;AAAA,MACT,OAAO;AACL,eAAO;AAAA,MACT;AAAA,IACF;AAGA,gBAAY,KAAK,UAAU,SAAS;AACpC,gBAAY,KAAK,UAAU,SAAS;AACpC,gBAAY,KAAK,YAAY,KAAK,SAAS,SAAS,CAAC;AACrD,gBAAY,KAAK,YAAY,KAAK,SAAS,SAAS,CAAC;AACrD,QAAI,SAAS,UAAU,QACnB,SAAS,UAAU;AACvB,QAAI,aAAa;AACjB,QAAI,gBAAgB,SAAS;AAE7B,QAAI,QAAQ,eAAe;AACzB,sBAAgB,KAAK,IAAI,eAAe,QAAQ,aAAa;AAAA,IAC/D;AAEA,QAAI,oBAAoB,mBAAmB,QAAQ,aAAa,QAAQ,qBAAqB,SAAS,mBAAmB;AACzH,QAAI,sBAAsB,KAAK,IAAI,IAAI;AACvC,QAAI,WAAW,CAAC;AAAA,MACd,QAAQ;AAAA,MACR,eAAe;AAAA,IACjB,CAAC;AAED,QAAI,SAAS,KAAK,cAAc,SAAS,CAAC,GAAG,WAAW,WAAW,CAAC;AAEpE,QAAI,SAAS,CAAC,EAAE,SAAS,KAAK,UAAU,SAAS,KAAK,QAAQ;AAE5D,aAAO,KAAK,CAAC;AAAA,QACX,OAAO,KAAK,KAAK,SAAS;AAAA,QAC1B,OAAO,UAAU;AAAA,MACnB,CAAC,CAAC;AAAA,IACJ;AAmBA,QAAI,wBAAwB,WACxB,wBAAwB;AAE5B,aAAS,iBAAiB;AACxB,eAAS,eAAe,KAAK,IAAI,uBAAuB,CAAC,UAAU,GAAG,gBAAgB,KAAK,IAAI,uBAAuB,UAAU,GAAG,gBAAgB,GAAG;AACpJ,YAAI,WAAW;AACf,YAAI,aAAa,SAAS,eAAe,CAAC,GACtC,UAAU,SAAS,eAAe,CAAC;AAEvC,YAAI,YAAY;AAEd,mBAAS,eAAe,CAAC,IAAI;AAAA,QAC/B;AAEA,YAAI,SAAS;AAEb,YAAI,SAAS;AAEX,cAAI,gBAAgB,QAAQ,SAAS;AACrC,mBAAS,WAAW,KAAK,iBAAiB,gBAAgB;AAAA,QAC5D;AAEA,YAAI,YAAY,cAAc,WAAW,SAAS,IAAI;AAEtD,YAAI,CAAC,UAAU,CAAC,WAAW;AAEzB,mBAAS,YAAY,IAAI;AACzB;AAAA,QACF;AAOA,YAAI,CAAC,aAAa,UAAU,WAAW,SAAS,IAAI,QAAQ,QAAQ;AAClE,qBAAW,KAAK,UAAU,SAAS,MAAM,QAAW,CAAC;AAAA,QACvD,OAAO;AACL,qBAAW,KAAK,UAAU,YAAY,QAAW,MAAM,CAAC;AAAA,QAC1D;AAEA,iBAAS,KAAK,cAAc,UAAU,WAAW,WAAW,YAAY;AAExE,YAAI,SAAS,SAAS,KAAK,UAAU,SAAS,KAAK,QAAQ;AAEzD,iBAAO,KAAK,YAAY,MAAM,SAAS,eAAe,WAAW,WAAW,KAAK,eAAe,CAAC;AAAA,QACnG,OAAO;AACL,mBAAS,YAAY,IAAI;AAEzB,cAAI,SAAS,SAAS,KAAK,QAAQ;AACjC,oCAAwB,KAAK,IAAI,uBAAuB,eAAe,CAAC;AAAA,UAC1E;AAEA,cAAI,SAAS,KAAK,QAAQ;AACxB,oCAAwB,KAAK,IAAI,uBAAuB,eAAe,CAAC;AAAA,UAC1E;AAAA,QACF;AAAA,MACF;AAEA;AAAA,IACF;AAMA,QAAI,UAAU;AACZ,OAAC,SAAS,OAAO;AACf,mBAAW,WAAY;AACrB,cAAI,aAAa,iBAAiB,KAAK,IAAI,IAAI,qBAAqB;AAClE,mBAAO,SAAS;AAAA,UAClB;AAEA,cAAI,CAAC,eAAe,GAAG;AACrB,iBAAK;AAAA,UACP;AAAA,QACF,GAAG,CAAC;AAAA,MACN,GAAG;AAAA,IACL,OAAO;AACL,aAAO,cAAc,iBAAiB,KAAK,IAAI,KAAK,qBAAqB;AACvE,YAAI,MAAM,eAAe;AAEzB,YAAI,KAAK;AACP,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,WAAW,SAAS,UAAU,MAAM,OAAO,SAAS,WAAW;AAC7D,QAAI,OAAO,KAAK;AAEhB,QAAI,QAAQ,KAAK,UAAU,SAAS,KAAK,YAAY,SAAS;AAC5D,aAAO;AAAA,QACL,QAAQ,KAAK,SAAS;AAAA,QACtB,eAAe;AAAA,UACb,OAAO,KAAK,QAAQ;AAAA,UACpB;AAAA,UACA;AAAA,UACA,mBAAmB,KAAK;AAAA,QAC1B;AAAA,MACF;AAAA,IACF,OAAO;AACL,aAAO;AAAA,QACL,QAAQ,KAAK,SAAS;AAAA,QACtB,eAAe;AAAA,UACb,OAAO;AAAA,UACP;AAAA,UACA;AAAA,UACA,mBAAmB;AAAA,QACrB;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EACA,eAAe,SAAS,cAAc,UAAU,WAAW,WAAW,cAAc;AAClF,QAAI,SAAS,UAAU,QACnB,SAAS,UAAU,QACnB,SAAS,SAAS,QAClB,SAAS,SAAS,cAClB,cAAc;AAElB,WAAO,SAAS,IAAI,UAAU,SAAS,IAAI,UAAU,KAAK,OAAO,UAAU,SAAS,CAAC,GAAG,UAAU,SAAS,CAAC,CAAC,GAAG;AAC9G;AACA;AACA;AAAA,IACF;AAEA,QAAI,aAAa;AACf,eAAS,gBAAgB;AAAA,QACvB,OAAO;AAAA,QACP,mBAAmB,SAAS;AAAA,MAC9B;AAAA,IACF;AAEA,aAAS,SAAS;AAClB,WAAO;AAAA,EACT;AAAA,EACA,QAAQ,SAAS,OAAO,MAAM,OAAO;AACnC,QAAI,KAAK,QAAQ,YAAY;AAC3B,aAAO,KAAK,QAAQ,WAAW,MAAM,KAAK;AAAA,IAC5C,OAAO;AACL,aAAO,SAAS,SAAS,KAAK,QAAQ,cAAc,KAAK,YAAY,MAAM,MAAM,YAAY;AAAA,IAC/F;AAAA,EACF;AAAA,EACA,aAAa,SAAS,YAAY,OAAO;AACvC,QAAI,MAAM,CAAC;AAEX,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAI,MAAM,CAAC,GAAG;AACZ,YAAI,KAAK,MAAM,CAAC,CAAC;AAAA,MACnB;AAAA,IACF;AAEA,WAAO;AAAA,EACT;AAAA,EACA,WAAW,SAAS,UAAU,OAAO;AACnC,WAAO;AAAA,EACT;AAAA,EACA,UAAU,SAAS,SAAS,OAAO;AACjC,WAAO,MAAM,MAAM,EAAE;AAAA,EACvB;AAAA,EACA,MAAM,SAAS,KAAK,OAAO;AACzB,WAAO,MAAM,KAAK,EAAE;AAAA,EACtB;AACF;AAEA,SAAS,YAAYA,OAAM,eAAe,WAAW,WAAW,iBAAiB;AAG/E,MAAI,aAAa,CAAC;AAClB,MAAI;AAEJ,SAAO,eAAe;AACpB,eAAW,KAAK,aAAa;AAC7B,oBAAgB,cAAc;AAC9B,WAAO,cAAc;AACrB,oBAAgB;AAAA,EAClB;AAEA,aAAW,QAAQ;AACnB,MAAI,eAAe,GACf,eAAe,WAAW,QAC1B,SAAS,GACT,SAAS;AAEb,SAAO,eAAe,cAAc,gBAAgB;AAClD,QAAI,YAAY,WAAW,YAAY;AAEvC,QAAI,CAAC,UAAU,SAAS;AACtB,UAAI,CAAC,UAAU,SAAS,iBAAiB;AACvC,YAAI,QAAQ,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK;AAC5D,gBAAQ,MAAM,IAAI,SAAUC,QAAO,GAAG;AACpC,cAAI,WAAW,UAAU,SAAS,CAAC;AACnC,iBAAO,SAAS,SAASA,OAAM,SAAS,WAAWA;AAAA,QACrD,CAAC;AACD,kBAAU,QAAQD,MAAK,KAAK,KAAK;AAAA,MACnC,OAAO;AACL,kBAAU,QAAQA,MAAK,KAAK,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK,CAAC;AAAA,MAC/E;AAEA,gBAAU,UAAU;AAEpB,UAAI,CAAC,UAAU,OAAO;AACpB,kBAAU,UAAU;AAAA,MACtB;AAAA,IACF,OAAO;AACL,gBAAU,QAAQA,MAAK,KAAK,UAAU,MAAM,QAAQ,SAAS,UAAU,KAAK,CAAC;AAC7E,gBAAU,UAAU;AAIpB,UAAI,gBAAgB,WAAW,eAAe,CAAC,EAAE,OAAO;AACtD,YAAI,MAAM,WAAW,eAAe,CAAC;AACrC,mBAAW,eAAe,CAAC,IAAI,WAAW,YAAY;AACtD,mBAAW,YAAY,IAAI;AAAA,MAC7B;AAAA,IACF;AAAA,EACF;AAKA,MAAI,iBAAiB,WAAW,eAAe,CAAC;AAEhD,MAAI,eAAe,KAAK,OAAO,eAAe,UAAU,aAAa,eAAe,SAAS,eAAe,YAAYA,MAAK,OAAO,IAAI,eAAe,KAAK,GAAG;AAC7J,eAAW,eAAe,CAAC,EAAE,SAAS,eAAe;AACrD,eAAW,IAAI;AAAA,EACjB;AAEA,SAAO;AACT;AAEA,IAAI,gBAAgB,IAAI,KAAK;AAsC7B,IAAI,oBAAoB;AACxB,IAAI,eAAe;AACnB,IAAI,WAAW,IAAI,KAAK;AAExB,SAAS,SAAS,SAAU,MAAM,OAAO;AACvC,MAAI,KAAK,QAAQ,YAAY;AAC3B,WAAO,KAAK,YAAY;AACxB,YAAQ,MAAM,YAAY;AAAA,EAC5B;AAEA,SAAO,SAAS,SAAS,KAAK,QAAQ,oBAAoB,CAAC,aAAa,KAAK,IAAI,KAAK,CAAC,aAAa,KAAK,KAAK;AAChH;AAEA,SAAS,WAAW,SAAU,OAAO;AAEnC,MAAI,SAAS,MAAM,MAAM,iCAAiC;AAE1D,WAAS,IAAI,GAAG,IAAI,OAAO,SAAS,GAAG,KAAK;AAE1C,QAAI,CAAC,OAAO,IAAI,CAAC,KAAK,OAAO,IAAI,CAAC,KAAK,kBAAkB,KAAK,OAAO,CAAC,CAAC,KAAK,kBAAkB,KAAK,OAAO,IAAI,CAAC,CAAC,GAAG;AACjH,aAAO,CAAC,KAAK,OAAO,IAAI,CAAC;AACzB,aAAO,OAAO,IAAI,GAAG,CAAC;AACtB;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAYA,IAAI,WAAW,IAAI,KAAK;AAExB,SAAS,WAAW,SAAU,OAAO;AACnC,MAAI,KAAK,QAAQ,iBAAiB;AAEhC,YAAQ,MAAM,QAAQ,SAAS,IAAI;AAAA,EACrC;AAEA,MAAI,WAAW,CAAC,GACZ,mBAAmB,MAAM,MAAM,WAAW;AAE9C,MAAI,CAAC,iBAAiB,iBAAiB,SAAS,CAAC,GAAG;AAClD,qBAAiB,IAAI;AAAA,EACvB;AAGA,WAAS,IAAI,GAAG,IAAI,iBAAiB,QAAQ,KAAK;AAChD,QAAI,OAAO,iBAAiB,CAAC;AAE7B,QAAI,IAAI,KAAK,CAAC,KAAK,QAAQ,gBAAgB;AACzC,eAAS,SAAS,SAAS,CAAC,KAAK;AAAA,IACnC,OAAO;AACL,UAAI,KAAK,QAAQ,kBAAkB;AACjC,eAAO,KAAK,KAAK;AAAA,MACnB;AAEA,eAAS,KAAK,IAAI;AAAA,IACpB;AAAA,EACF;AAEA,SAAO;AACT;AAYA,IAAI,eAAe,IAAI,KAAK;AAE5B,aAAa,WAAW,SAAU,OAAO;AACvC,SAAO,MAAM,MAAM,uBAAuB;AAC5C;AAMA,IAAI,UAAU,IAAI,KAAK;AAEvB,QAAQ,WAAW,SAAU,OAAO;AAClC,SAAO,MAAM,MAAM,eAAe;AACpC;AAMA,SAAS,QAAQ,KAAK;AACpB;AAEA,MAAI,OAAO,WAAW,cAAc,OAAO,OAAO,aAAa,UAAU;AACvE,cAAU,SAAUE,MAAK;AACvB,aAAO,OAAOA;AAAA,IAChB;AAAA,EACF,OAAO;AACL,cAAU,SAAUA,MAAK;AACvB,aAAOA,QAAO,OAAO,WAAW,cAAcA,KAAI,gBAAgB,UAAUA,SAAQ,OAAO,YAAY,WAAW,OAAOA;AAAA,IAC3H;AAAA,EACF;AAEA,SAAO,QAAQ,GAAG;AACpB;AAoFA,IAAI,0BAA0B,OAAO,UAAU;AAC/C,IAAI,WAAW,IAAI,KAAK;AAGxB,SAAS,kBAAkB;AAC3B,SAAS,WAAW,SAAS;AAE7B,SAAS,YAAY,SAAU,OAAO;AACpC,MAAI,gBAAgB,KAAK,SACrB,uBAAuB,cAAc,sBACrC,wBAAwB,cAAc,mBACtC,oBAAoB,0BAA0B,SAAS,SAAU,GAAG,GAAG;AACzE,WAAO,OAAO,MAAM,cAAc,uBAAuB;AAAA,EAC3D,IAAI;AACJ,SAAO,OAAO,UAAU,WAAW,QAAQ,KAAK,UAAU,aAAa,OAAO,MAAM,MAAM,iBAAiB,GAAG,mBAAmB,IAAI;AACvI;AAEA,SAAS,SAAS,SAAU,MAAM,OAAO;AACvC,SAAO,KAAK,UAAU,OAAO,KAAK,UAAU,KAAK,QAAQ,cAAc,IAAI,GAAG,MAAM,QAAQ,cAAc,IAAI,CAAC;AACjH;AAOA,SAAS,aAAa,KAAK,OAAO,kBAAkB,UAAU,KAAK;AACjE,UAAQ,SAAS,CAAC;AAClB,qBAAmB,oBAAoB,CAAC;AAExC,MAAI,UAAU;AACZ,UAAM,SAAS,KAAK,GAAG;AAAA,EACzB;AAEA,MAAI;AAEJ,OAAK,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,GAAG;AACpC,QAAI,MAAM,CAAC,MAAM,KAAK;AACpB,aAAO,iBAAiB,CAAC;AAAA,IAC3B;AAAA,EACF;AAEA,MAAI;AAEJ,MAAI,qBAAqB,wBAAwB,KAAK,GAAG,GAAG;AAC1D,UAAM,KAAK,GAAG;AACd,uBAAmB,IAAI,MAAM,IAAI,MAAM;AACvC,qBAAiB,KAAK,gBAAgB;AAEtC,SAAK,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK,GAAG;AAClC,uBAAiB,CAAC,IAAI,aAAa,IAAI,CAAC,GAAG,OAAO,kBAAkB,UAAU,GAAG;AAAA,IACnF;AAEA,UAAM,IAAI;AACV,qBAAiB,IAAI;AACrB,WAAO;AAAA,EACT;AAEA,MAAI,OAAO,IAAI,QAAQ;AACrB,UAAM,IAAI,OAAO;AAAA,EACnB;AAEA,MAAI,QAAQ,GAAG,MAAM,YAAY,QAAQ,MAAM;AAC7C,UAAM,KAAK,GAAG;AACd,uBAAmB,CAAC;AACpB,qBAAiB,KAAK,gBAAgB;AAEtC,QAAI,aAAa,CAAC,GACd;AAEJ,SAAK,QAAQ,KAAK;AAEhB,UAAI,IAAI,eAAe,IAAI,GAAG;AAC5B,mBAAW,KAAK,IAAI;AAAA,MACtB;AAAA,IACF;AAEA,eAAW,KAAK;AAEhB,SAAK,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK,GAAG;AACzC,aAAO,WAAW,CAAC;AACnB,uBAAiB,IAAI,IAAI,aAAa,IAAI,IAAI,GAAG,OAAO,kBAAkB,UAAU,IAAI;AAAA,IAC1F;AAEA,UAAM,IAAI;AACV,qBAAiB,IAAI;AAAA,EACvB,OAAO;AACL,uBAAmB;AAAA,EACrB;AAEA,SAAO;AACT;AAEA,IAAI,YAAY,IAAI,KAAK;AAEzB,UAAU,WAAW,SAAU,OAAO;AACpC,SAAO,MAAM,MAAM;AACrB;AAEA,UAAU,OAAO,UAAU,cAAc,SAAU,OAAO;AACxD,SAAO;AACT;;;AC5mBA,IAAM,kBAAkB,oBAAI,IAAI;AAAA,EAC9B,CAAC,SAAS,OAAO;AAAA,EACjB,CAAC,UAAU,QAAQ;AACrB,CAAC;AAqFM,IAAM,aAAa,CAAC,QACzB,CAAC,GAAG,eAAe,EAAE,KAAK,CAAC,CAAC,EAAE,YAAY,MAAM,IAAI,WAAW,YAAY,CAAC;;;AC5G9E,IAAM,eAAe;AACrB,IAAI,CAAC,cAAc;AACjB,QAAM,IAAI,MAAM,6BAA6B;AAC/C;AAEA,IAAM,eAAe;AACrB,IAAM,uBAAuB;AAE7B,SAAS,SAAS,QAAQ;AAAA,EACxB,OAAO;AAAA,EACP,OAAO;AAAA,EACP,SAAS,MAAM;AACb,QAAI,CAAC,oBAAoB;AACvB;AAAA,IACF;AAEA,YAAQ,QAAQ,YAAY,cAAc,kBAAkB;AAAA,EAC9D;AACF,CAAC;AACD,IAAM,+BACJ;AAEF,SAAS,SAAS,QAAQ;AAAA,EACxB,OAAO;AAAA,EACP,OAAO;AAAA,EACP,SAAS,MAAM;AACb;AAAA,MACE;AAAA,IACF;AAAA,EACF;AACF,CAAC;AAED,IAAM,oBAAoB;AAE1B,SAAS,SAAS,QAAQ;AAAA,EACxB,OAAO;AAAA,EACP,OAAO;AAAA,EACP,SAAS,MAAM;AACb,UAAM,OAAO,OAAO,MAAM;AAC1B,QAAI,CAAC,MAAM;AACT;AAAA,IACF;AAEA,aAAS,SAAS,IAAI,IAAI,gBAAgB;AAAA,MACxC,MAAM,8DAAuD;AAAA,QAC3D;AAAA,MACF,CAAC;AAAA,EACL,KACC,MAAM,IAAI,EACV,IAAI,CAAC,SAAS,KAAK,IAAI,EAAE,EACzB,KAAK,IAAI,CAAC;AAAA,IACT,CAAC,CAAC;AAAA,EACJ;AACF,CAAC;AAED,IAAM,eAAe,SAAS,cAAc,OAAO;AACnD,SAAS,KAAK,OAAO,YAAY;AACjC,IAAM,WAAW,CAAC,EAAE,iBAAiB,MAAqC;AACxE,eAAa,cAAc;AAAA,OACtB,IAAI,OAAO,oBAAoB,CAAC;AAAA,QAC/B,mBAAmB,KAAK,gBAAgB;AAAA;AAAA;AAAA,OAGzC,IAAI,OAAO,4BAA4B,CAAC;AAAA;AAAA,QAEvC,mBAAmB,mBAAmB,EAAE;AAAA;AAAA;AAAA,OAGzC,IAAI,OAAO,iBAAiB,CAAC;AAAA,QAC5B,mBAAmB,KAAK,gBAAgB;AAAA;AAAA;AAGhD;AACA,SAAS,EAAE,kBAAkB,MAAM,CAAC;AAEpC,IAAI;AACJ,IAAM,sBAAsB,YAAY;AAEtC,QAAM,YAAY,SAAS,KAAK;AAChC,MAAI,CAAC,WAAW;AACd;AAAA,EACF;AAEA,QAAM,YAAsB,CAAC;AAC7B,OAAK;AAAA;AAAA,IAEH,SAAS,KAAK;AAAA,IACd,CAAC,MAAM,UAAmB;AACxB,YAAM,WAAW,gBAAgB,KAAK;AACtC,UAAI,UAAU;AACZ,kBAAU,KAAK,QAAQ;AAAA,MACzB;AAEA,aAAO;AAAA,IACT;AAAA,EACF;AACA,QAAM,kBAAkB,CAAC,GAAG,IAAI,IAAI,SAAS,CAAC;AAE9C,uBAAqB;AAAA,IACnB,MAAM;AAAA;AAAA,IAEN,aAAa,SAAS,QAAQ;AAAA,IAC9B;AAAA,IACA,WAAW;AAAA,EACb;AACA,WAAS,EAAE,kBAAkB,QAAQ,gBAAgB,MAAM,EAAE,CAAC;AAChE;AAEA,IAAM,kBAAkB,CAAC,UAAmB;AAC1C,MAAI,OAAO,UAAU,YAAY,UAAU,MAAM;AAC/C;AAAA,EACF;AAEA,MAAI,EAAE,UAAU,UAAU,MAAM,SAAS,QAAQ;AAC/C;AAAA,EACF;AACA,MACE,EAAE,UAAU,UACZ,OAAO,MAAM,SAAS,YACtB,MAAM,SAAS,MACf;AACA;AAAA,EACF;AACA,QAAM,EAAE,KAAK,IAAI;AAEjB,MAAI,aAAa,MAAM;AACrB;AAAA,EACF;AACA,MAAI,EAAE,UAAU,SAAS,OAAO,KAAK,SAAS,UAAU;AACtD;AAAA,EACF;AACA,QAAM,EAAE,KAAK,IAAI;AAEjB,MAAI,CAAC,WAAW,IAAI,GAAG;AACrB;AAAA,EACF;AAEA,SAAO;AACT;AAEA,oBAAoB;AAEpB,SAAS,GAAG,iBAAiB,mBAAmB;AAEhD,SAAS,GAAG,gBAAgB,mBAAmB;",
  "names": ["diff", "value", "obj"]
}
